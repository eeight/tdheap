<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>6. Callgrind: a call graph profiler</title>
<link rel="stylesheet" href="vg_basic.css" type="text/css">
<meta name="generator" content="DocBook XSL Stylesheets V1.69.1">
<link rel="start" href="index.html" title="Valgrind Documentation">
<link rel="up" href="manual.html" title="Valgrind User Manual">
<link rel="prev" href="cg-manual.html" title="5. Cachegrind: a cache and branch profiler">
<link rel="next" href="hg-manual.html" title="7. Helgrind: a thread error detector">
</head>
<body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF">
<div><table class="nav" width="100%" cellspacing="3" cellpadding="3" border="0" summary="Navigation header"><tr>
<td width="22px" align="center" valign="middle"><a accesskey="p" href="cg-manual.html"><img src="images/prev.png" width="18" height="21" border="0" alt="Prev"></a></td>
<td width="25px" align="center" valign="middle"><a accesskey="u" href="manual.html"><img src="images/up.png" width="21" height="18" border="0" alt="Up"></a></td>
<td width="31px" align="center" valign="middle"><a accesskey="h" href="index.html"><img src="images/home.png" width="27" height="20" border="0" alt="Up"></a></td>
<th align="center" valign="middle">Valgrind User Manual</th>
<td width="22px" align="center" valign="middle"><a accesskey="n" href="hg-manual.html"><img src="images/next.png" width="18" height="21" border="0" alt="Next"></a></td>
</tr></table></div>
<div class="chapter" lang="en">
<div class="titlepage"><div><div><h2 class="title">
<a name="cl-manual"></a>6. Callgrind: a call graph profiler</h2></div></div></div>
<div class="toc">
<p><b>Table of Contents</b></p>
<dl>
<dt><span class="sect1"><a href="cl-manual.html#cl-manual.use">6.1. Overview</a></span></dt>
<dd><dl>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.functionality">6.1.1. Functionality</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.basics">6.1.2. Basic Usage</a></span></dt>
</dl></dd>
<dt><span class="sect1"><a href="cl-manual.html#cl-manual.usage">6.2. Advanced Usage</a></span></dt>
<dd><dl>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.dumps">6.2.1. Multiple profiling dumps from one program run</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.limits">6.2.2. Limiting the range of collected events</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.cycles">6.2.3. Avoiding cycles</a></span></dt>
</dl></dd>
<dt><span class="sect1"><a href="cl-manual.html#cl-manual.options">6.3. Command line option reference</a></span></dt>
<dd><dl>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.options.misc">6.3.1. Miscellaneous options</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.options.creation">6.3.2. Dump creation options</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.options.activity">6.3.3. Activity options</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.options.collection">6.3.4. Data collection options</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.options.separation">6.3.5. Cost entity separation options</a></span></dt>
<dt><span class="sect2"><a href="cl-manual.html#cl-manual.options.simulation">6.3.6. Cache simulation options</a></span></dt>
</dl></dd>
</dl>
</div>
<div class="sect1" lang="en">
<div class="titlepage"><div><div><h2 class="title" style="clear: both">
<a name="cl-manual.use"></a>6.1. Overview</h2></div></div></div>
<p>Callgrind is a profiling tool that can
construct a call graph for a program's run.
By default, the collected data consists of
the number of instructions executed, their relationship
to source lines, the caller/callee relationship between functions,
and the numbers of such calls.
Optionally, a cache simulator (similar to cachegrind) can produce
further information about the memory access behavior of the application.
</p>
<p>The profile data is written out to a file at program
termination. For presentation of the data, and interactive control
of the profiling, two command line tools are provided:</p>
<div class="variablelist"><dl>
<dt><span class="term"><span><strong class="command">callgrind_annotate</strong></span></span></dt>
<dd>
<p>This command reads in the profile data, and prints a
    sorted lists of functions, optionally with source annotation.</p>
<p>For graphical visualization of the data, try
    <a href="http://kcachegrind.sourceforge.net/cgi-bin/show.cgi/KcacheGrindIndex" target="_top">KCachegrind</a>, which is a KDE/Qt based
    GUI that makes it easy to navigate the large amount of data that
    Callgrind produces.</p>
</dd>
<dt><span class="term"><span><strong class="command">callgrind_control</strong></span></span></dt>
<dd><p>This command enables you to interactively observe and control 
    the status of currently running applications, without stopping
    the application.  You can 
    get statistics information as well as the current stack trace, and
    you can request zeroing of counters or dumping of profile data.</p></dd>
</dl></div>
<p>To use Callgrind, you must specify 
<code class="computeroutput">--tool=callgrind</code> on the Valgrind 
command line.</p>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.functionality"></a>6.1.1. Functionality</h3></div></div></div>
<p>Cachegrind collects flat profile data: event counts (data reads,
cache misses, etc.) are attributed directly to the function they
occurred in.  This cost attribution mechanism is
called <span class="emphasis"><em>self</em></span> or <span class="emphasis"><em>exclusive</em></span>
attribution.</p>
<p>Callgrind extends this functionality by propagating costs
across function call boundaries.  If function <code class="code">foo</code> calls
<code class="code">bar</code>, the costs from <code class="code">bar</code> are added into
<code class="code">foo</code>'s costs.  When applied to the program as a whole,
this builds up a picture of so called <span class="emphasis"><em>inclusive</em></span>
costs, that is, where the cost of each function includes the costs of
all functions it called, directly or indirectly.</p>
<p>As an example, the inclusive cost of
<code class="computeroutput">main</code> should be almost 100 percent
of the total program cost.  Because of costs arising before 
<code class="computeroutput">main</code> is run, such as
initialization of the run time linker and construction of global C++
objects, the inclusive cost of <code class="computeroutput">main</code>
is not exactly 100 percent of the total program cost.</p>
<p>Together with the call graph, this allows you to find the
specific call chains starting from
<code class="computeroutput">main</code> in which the majority of the
program's costs occur.  Caller/callee cost attribution is also useful
for profiling functions called from multiple call sites, and where
optimization opportunities depend on changing code in the callers, in
particular by reducing the call count.</p>
<p>Callgrind's cache simulation is based on the 
<a href="http://www.valgrind.org/info/tools.html#cachegrind" target="_top">Cachegrind tool</a>. Read 
<a href="http://www.valgrind.org/docs/manual/cg-manual.html" target="_top">Cachegrind's documentation</a> first.
The material below describes the features supported in addition to 
Cachegrind's features.</p>
<p>Callgrind's ability to detect function calls and returns depends
on the instruction set of the platform it is run on.  It works best
on x86 and amd64, and unfortunately currently does not work so well
on PowerPC code.  This is because there are no explicit call or return
instructions in the PowerPC instruction set, so Callgrind has to rely
on heuristics to detect calls and returns.</p>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.basics"></a>6.1.2. Basic Usage</h3></div></div></div>
<p>As with Cachegrind, you probably want to compile with debugging info
  (the -g flag), but with optimization turned on.</p>
<p>To start a profile run for a program, execute:
  </p>
<pre class="screen">valgrind --tool=callgrind [callgrind options] your-program [program options]</pre>
<p>
  </p>
<p>While the simulation is running, you can observe execution with
  </p>
<pre class="screen">callgrind_control -b</pre>
<p>
  This will print out the current backtrace. To annotate the backtrace with
  event counts, run
  </p>
<pre class="screen">callgrind_control -e -b</pre>
<p>
  </p>
<p>After program termination, a profile data file named 
  <code class="computeroutput">callgrind.out.&lt;pid&gt;</code>
  is generated, where <span class="emphasis"><em>pid</em></span> is the process ID 
  of the program being profiled.
  The data file contains information about the calls made in the
  program among the functions executed, together with events of type
  <span><strong class="command">Instruction Read Accesses</strong></span> (Ir).</p>
<p>To generate a function-by-function summary from the profile
  data file, use
  </p>
<pre class="screen">callgrind_annotate [options] callgrind.out.&lt;pid&gt;</pre>
<p>
  This summary is similar to the output you get from a Cachegrind
  run with <code class="computeroutput">cg_annotate</code>: the list
  of functions is ordered by exclusive cost of functions, which also
  are the ones that are shown.
  Important for the additional features of Callgrind are
  the following two options:</p>
<div class="itemizedlist"><ul type="disc">
<li><p><code class="option">--inclusive=yes</code>: Instead of using
      exclusive cost of functions as sorting order, use and show
      inclusive cost.</p></li>
<li><p><code class="option">--tree=both</code>: Interleave into the
      top level list of functions, information on the callers and the callees
      of each function. In these lines, which represents executed
      calls, the cost gives the number of events spent in the call.
      Indented, above each function, there is the list of callers,
      and below, the list of callees. The sum of events in calls to
      a given function (caller lines), as well as the sum of events in
      calls from the function (callee lines) together with the self
      cost, gives the total inclusive cost of the function.</p></li>
</ul></div>
<p>Use <code class="option">--auto=yes</code> to get annotated source code
  for all relevant functions for which the source can be found. In
  addition to source annotation as produced by
  <code class="computeroutput">cg_annotate</code>, you will see the
  annotated call sites with call counts. For all other options, 
  consult the (Cachegrind) documentation for
  <code class="computeroutput">cg_annotate</code>.
  </p>
<p>For better call graph browsing experience, it is highly recommended
  to use <a href="http://kcachegrind.sourceforge.net/cgi-bin/show.cgi/KcacheGrindIndex" target="_top">KCachegrind</a>.
  If your code
  has a significant fraction of its cost in <span class="emphasis"><em>cycles</em></span> (sets
  of functions calling each other in a recursive manner), you have to
  use KCachegrind, as <code class="computeroutput">callgrind_annotate</code>
  currently does not do any cycle detection, which is important to get correct
  results in this case.</p>
<p>If you are additionally interested in measuring the 
  cache behavior of your 
  program, use Callgrind with the option
  <code class="option"><a href="cl-manual.html#opt.simulate-cache">--simulate-cache</a>=yes.</code>
  However, expect a  further slow down approximately by a factor of 2.</p>
<p>If the program section you want to profile is somewhere in the
  middle of the run, it is beneficial to 
  <span class="emphasis"><em>fast forward</em></span> to this section without any 
  profiling, and then switch on profiling.  This is achieved by using
  the command line option
  <code class="option"><a href="cl-manual.html#opt.instr-atstart">--instr-atstart</a>=no</code> 
  and running, in a shell,
  <code class="computeroutput">callgrind_control -i on</code> just before the 
  interesting code section is executed. To exactly specify
  the code position where profiling should start, use the client request
  <code class="computeroutput">CALLGRIND_START_INSTRUMENTATION</code>.</p>
<p>If you want to be able to see assembly code level annotation, specify
  <code class="option"><a href="cl-manual.html#opt.dump-instr">--dump-instr</a>=yes</code>. This will produce
  profile data at instruction granularity. Note that the resulting profile
  data
  can only be viewed with KCachegrind. For assembly annotation, it also is
  interesting to see more details of the control flow inside of functions,
  ie. (conditional) jumps. This will be collected by further specifying
  <code class="option"><a href="cl-manual.html#opt.collect-jumps">--collect-jumps</a>=yes</code>.</p>
</div>
</div>
<div class="sect1" lang="en">
<div class="titlepage"><div><div><h2 class="title" style="clear: both">
<a name="cl-manual.usage"></a>6.2. Advanced Usage</h2></div></div></div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.dumps"></a>6.2.1. Multiple profiling dumps from one program run</h3></div></div></div>
<p>Sometimes you are not interested in characteristics of a full 
  program run, but only of a small part of it, for example execution of one
  algorithm.  If there are multiple algorithms, or one algorithm 
  running with different input data, it may even be useful to get different
  profile information for different parts of a single program run.</p>
<p>Profile data files have names of the form
</p>
<pre class="screen">
callgrind.out.<span class="emphasis"><em>pid</em></span>.<span class="emphasis"><em>part</em></span>-<span class="emphasis"><em>threadID</em></span>
</pre>
<p>
  </p>
<p>where <span class="emphasis"><em>pid</em></span> is the PID of the running 
  program, <span class="emphasis"><em>part</em></span> is a number incremented on each
  dump (".part" is skipped for the dump at program termination), and 
  <span class="emphasis"><em>threadID</em></span> is a thread identification 
  ("-threadID" is only used if you request dumps of individual 
  threads with <code class="option"><a href="cl-manual.html#opt.separate-threads">--separate-threads</a>=yes</code>).</p>
<p>There are different ways to generate multiple profile dumps 
  while a program is running under Callgrind's supervision.  Nevertheless,
  all methods trigger the same action, which is "dump all profile 
  information since the last dump or program start, and zero cost 
  counters afterwards".  To allow for zeroing cost counters without
  dumping, there is a second action "zero all cost counters now". 
  The different methods are:</p>
<div class="itemizedlist"><ul type="disc">
<li><p><span><strong class="command">Dump on program termination.</strong></span>
      This method is the standard way and doesn't need any special
      action on your part.</p></li>
<li>
<p><span><strong class="command">Spontaneous, interactive dumping.</strong></span> Use
      </p>
<pre class="screen">callgrind_control -d [hint [PID/Name]]</pre>
<p> to 
      request the dumping of profile information of the supervised
      application with PID or Name.  <span class="emphasis"><em>hint</em></span> is an
      arbitrary string you can optionally specify to later be able to
      distinguish profile dumps.  The control program will not terminate
      before the dump is completely written.  Note that the application
      must be actively running for detection of the dump command. So,
      for a GUI application, resize the window, or for a server, send a
      request.</p>
<p>If you are using <a href="http://kcachegrind.sourceforge.net/cgi-bin/show.cgi/KcacheGrindIndex" target="_top">KCachegrind</a>
      for browsing of profile information, you can use the toolbar
      button <span><strong class="command">Force dump</strong></span>. This will request a dump
      and trigger a reload after the dump is written.</p>
</li>
<li><p><span><strong class="command">Periodic dumping after execution of a specified
      number of basic blocks</strong></span>. For this, use the command line
      option <code class="option"><a href="cl-manual.html#opt.dump-every-bb">--dump-every-bb</a>=count</code>.
      </p></li>
<li>
<p><span><strong class="command">Dumping at enter/leave of specified functions.</strong></span>
      Use the
      option <code class="option"><a href="cl-manual.html#opt.dump-before">--dump-before</a>=function</code>
      and <code class="option"><a href="cl-manual.html#opt.dump-after">--dump-after</a>=function</code>.
      To zero cost counters before entering a function, use
      <code class="option"><a href="cl-manual.html#opt.zero-before">--zero-before</a>=function</code>.</p>
<p>You can specify these options multiple times for different
      functions. Function specifications support wildcards: eg. use
      <code class="option"><a href="cl-manual.html#opt.dump-before">--dump-before</a>='foo*'</code> to
      generate dumps before entering any function starting with 
      <span class="emphasis"><em>foo</em></span>.</p>
</li>
<li>
<p><span><strong class="command">Program controlled dumping.</strong></span>
      Put </p>
<pre class="screen">#include &lt;valgrind/callgrind.h&gt;</pre>
<p>
      into your source and add 
      <code class="computeroutput">CALLGRIND_DUMP_STATS;</code> when you
      want a dump to happen. Use 
      <code class="computeroutput">CALLGRIND_ZERO_STATS;</code> to only 
      zero cost centers.</p>
<p>In Valgrind terminology, this method is called "Client
      requests".  The given macros generate a special instruction
      pattern with no effect at all (i.e. a NOP). When run under
      Valgrind, the CPU simulation engine detects the special
      instruction pattern and triggers special actions like the ones
      described above.</p>
</li>
</ul></div>
<p>If you are running a multi-threaded application and specify the
  command line option <code class="option"><a href="cl-manual.html#opt.separate-threads">--separate-threads</a>=yes</code>, 
  every thread will be profiled on its own and will create its own
  profile dump. Thus, the last two methods will only generate one dump
  of the currently running thread. With the other methods, you will get
  multiple dumps (one for each thread) on a dump request.</p>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.limits"></a>6.2.2. Limiting the range of collected events</h3></div></div></div>
<p>For aggregating events (function enter/leave,
  instruction execution, memory access) into event numbers,
  first, the events must be recognizable by Callgrind, and second,
  the collection state must be switched on.</p>
<p>Event collection is only possible if <span class="emphasis"><em>instrumentation</em></span>
  for program code is switched on. This is the default, but for faster
  execution (identical to <code class="computeroutput">valgrind --tool=none</code>),
  it can be switched off until the program reaches a state in which
  you want to start collecting profiling data.  
  Callgrind can start without instrumentation
  by specifying option <code class="option"><a href="cl-manual.html#opt.instr-atstart">--instr-atstart</a>=no</code>.
  Instrumentation can be switched on interactively
  with </p>
<pre class="screen">callgrind_control -i on</pre>
<p>
  and off by specifying "off" instead of "on".
  Furthermore, instrumentation state can be programatically changed with
  the macros <code class="computeroutput">CALLGRIND_START_INSTRUMENTATION;</code>
  and <code class="computeroutput">CALLGRIND_STOP_INSTRUMENTATION;</code>.
  </p>
<p>In addition to enabling instrumentation, you must also enable
  event collection for the parts of your program you are interested in.
  By default, event collection is enabled everywhere.
  You can limit collection to a specific function
  by using 
  <code class="option"><a href="cl-manual.html#opt.toggle-collect">--toggle-collect</a>=function</code>. 
  This will toggle the collection state on entering and leaving
  the specified functions.
  When this option is in effect, the default collection state
  at program start is "off".  Only events happening while running
  inside of the given function will be collected. Recursive
  calls of the given function do not trigger any action.</p>
<p>It is important to note that with instrumentation switched off, the
  cache simulator cannot see any memory access events, and thus, any
  simulated cache state will be frozen and wrong without instrumentation.
  Therefore, to get useful cache events (hits/misses) after switching on
  instrumentation, the cache first must warm up,
  probably leading to many <span class="emphasis"><em>cold misses</em></span>
  which would not have happened in reality. If you do not want to see these,
  start event collection a few million instructions after you have switched
  on instrumentation.</p>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.cycles"></a>6.2.3. Avoiding cycles</h3></div></div></div>
<p>Informally speaking, a cycle is a group of functions which
  call each other in a recursive way.</p>
<p>Formally speaking, a cycle is a nonempty set S of functions,
  such that for every pair of functions F and G in S, it is possible
  to call from F to G (possibly via intermediate functions) and also
  from G to F.  Furthermore, S must be maximal -- that is, be the
  largest set of functions satisfying this property.  For example, if
  a third function H is called from inside S and calls back into S,
  then H is also part of the cycle and should be included in S.</p>
<p>Recursion is quite usual in programs, and therefore, cycles
  sometimes appear in the call graph output of Callgrind. However,
  the title of this chapter should raise two questions: What is bad
  about cycles which makes you want to avoid them? And: How can
  cycles be avoided without changing program code?</p>
<p>Cycles are not bad in itself, but tend to make performance
  analysis of your code harder. This is because inclusive costs
  for calls inside of a cycle are meaningless. The definition of
  inclusive cost, ie. self cost of a function plus inclusive cost
  of its callees, needs a topological order among functions. For
  cycles, this does not hold true: callees of a function in a cycle include
  the function itself. Therefore, KCachegrind does cycle detection
  and skips visualization of any inclusive cost for calls inside
  of cycles. Further, all functions in a cycle are collapsed into artifical
  functions called like <code class="computeroutput">Cycle 1</code>.</p>
<p>Now, when a program exposes really big cycles (as is
  true for some GUI code, or in general code using event or callback based
  programming style), you loose the nice property to let you pinpoint
  the bottlenecks by following call chains from
  <code class="computeroutput">main()</code>, guided via
  inclusive cost. In addition, KCachegrind looses its ability to show
  interesting parts of the call graph, as it uses inclusive costs to
  cut off uninteresting areas.</p>
<p>Despite the meaningless of inclusive costs in cycles, the big
  drawback for visualization motivates the possibility to temporarily
  switch off cycle detection in KCachegrind, which can lead to
  misguiding visualization. However, often cycles appear because of
  unlucky superposition of independent call chains in a way that
  the profile result will see a cycle. Neglecting uninteresting
  calls with very small measured inclusive cost would break these
  cycles. In such cases, incorrect handling of cycles by not detecting
  them still gives meaningful profiling visualization.</p>
<p>It has to be noted that currently, <span><strong class="command">callgrind_annotate</strong></span>
  does not do any cycle detection at all. For program executions with function
  recursion, it e.g. can print nonsense inclusive costs way above 100%.</p>
<p>After describing why cycles are bad for profiling, it is worth
  talking about cycle avoidance. The key insight here is that symbols in
  the profile data do not have to exactly match the symbols found in the
  program. Instead, the symbol name could encode additional information
  from the current execution context such as recursion level of the
  current function, or even some part of the call chain leading to the
  function. While encoding of additional information into symbols is
  quite capable of avoiding cycles, it has to be used carefully to not cause
  symbol explosion. The latter imposes large memory requirement for Callgrind
  with possible out-of-memory conditions, and big profile data files.</p>
<p>A further possibility to avoid cycles in Callgrind's profile data
  output is to simply leave out given functions in the call graph. Of course, this
  also skips any call information from and to an ignored function, and thus can
  break a cycle. Candidates for this typically are dispatcher functions in event
  driven code. The option to ignore calls to a function is
  <code class="option"><a href="cl-manual.html#opt.fn-skip">--fn-skip</a>=function</code>. Aside from
  possibly breaking cycles, this is used in Callgrind to skip
  trampoline functions in the PLT sections
  for calls to functions in shared libraries. You can see the difference
  if you profile with <code class="option"><a href="cl-manual.html#opt.skip-plt">--skip-plt</a>=no</code>.
  If a call is ignored, its cost events will be propagated to the
  enclosing function.</p>
<p>If you have a recursive function, you can distinguish the first
  10 recursion levels by specifying
  <code class="option"><a href="cl-manual.html#opt.separate-recs-num">--separate-recs10</a>=function</code>.  
  Or for all functions with 
  <code class="option"><a href="cl-manual.html#opt.separate-recs">--separate-recs</a>=10</code>, but this will 
  give you much bigger profile data files.  In the profile data, you will see
  the recursion levels of "func" as the different functions with names
  "func", "func'2", "func'3" and so on.</p>
<p>If you have call chains "A &gt; B &gt; C" and "A &gt; C &gt; B"
  in your program, you usually get a "false" cycle "B &lt;&gt; C". Use 
  <code class="option"><a href="cl-manual.html#opt.separate-callers-num">--separate-callers2</a>=B</code> 
  <code class="option"><a href="cl-manual.html#opt.separate-callers-num">--separate-callers2</a>=C</code>,
  and functions "B" and "C" will be treated as different functions 
  depending on the direct caller. Using the apostrophe for appending 
  this "context" to the function name, you get "A &gt; B'A &gt; C'B" 
  and "A &gt; C'A &gt; B'C", and there will be no cycle. Use 
  <code class="option"><a href="cl-manual.html#opt.separate-callers">--separate-callers</a>=2</code> to get a 2-caller 
  dependency for all functions.  Note that doing this will increase
  the size of profile data files.</p>
</div>
</div>
<div class="sect1" lang="en">
<div class="titlepage"><div><div><h2 class="title" style="clear: both">
<a name="cl-manual.options"></a>6.3. Command line option reference</h2></div></div></div>
<p>
In the following, options are grouped into classes, in the same order as
the output of <code class="computeroutput">callgrind --help</code>.
</p>
<p>
Some options allow the specification of a function/symbol name, such as
<code class="option"><a href="cl-manual.html#opt.dump-before">--dump-before</a>=function</code>, or
<code class="option"><a href="cl-manual.html#opt.fn-skip">--fn-skip</a>=function</code>. All these options
can be specified multiple times for different functions.
In addition, the function specifications actually are patterns by supporting
the use of wildcards '*' (zero or more arbitrary characters) and '?'
(exactly one arbitrary character), similar to file name globbing in the
shell. This feature is important especially for C++, as without wildcard
usage, the function would have to be specified in full extent, including
parameter signature. </p>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.options.misc"></a>6.3.1. Miscellaneous options</h3></div></div></div>
<div class="variablelist">
<a name="cl.opts.list.misc"></a><dl>
<dt><span class="term"><code class="option">--help</code></span></dt>
<dd><p>Show summary of options. This is a short version of this
      manual section.</p></dd>
<dt><span class="term"><code class="option">--version</code></span></dt>
<dd><p>Show version of callgrind.</p></dd>
</dl>
</div>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.options.creation"></a>6.3.2. Dump creation options</h3></div></div></div>
<p>
These options influence the name and format of the profile data files.
</p>
<div class="variablelist">
<a name="cl.opts.list.creation"></a><dl>
<dt>
<a name="opt.callgrind-out-file"></a><span class="term">
      <code class="option">--callgrind-out-file=&lt;file&gt; </code>
    </span>
</dt>
<dd><p>Write the profile data to
            <code class="computeroutput">file</code> rather than to the default
            output file,
            <code class="computeroutput">callgrind.out.&lt;pid&gt;</code>.  The
            <code class="option">%p</code> and <code class="option">%q</code> format specifiers
            can be used to embed the process ID and/or the contents of an
            environment variable in the name, as is the case for the core
            option <code class="option">--log-file</code>.  See <a href="manual-core.html#manual-core.basicopts" title="2.6.2. Basic Options">here</a> for details.
            When multiple dumps are made, the file name
            is modified further; see below.</p></dd>
<dt>
<a name="opt.dump-instr"></a><span class="term">
      <code class="option">--dump-instr=&lt;no|yes&gt; [default: no] </code>
    </span>
</dt>
<dd><p>This specifies that event counting should be performed at
      per-instruction granularity.
      This allows for assembly code
      annotation.  Currently the results can only be 
      displayed by KCachegrind.</p></dd>
<dt>
<a name="opt.dump-line"></a><span class="term">
      <code class="option">--dump-line=&lt;no|yes&gt; [default: yes] </code>
    </span>
</dt>
<dd><p>This specifies that event counting should be performed at
      source line granularity. This allows source
      annotation for sources which are compiled with debug information ("-g").</p></dd>
<dt>
<a name="opt.compress-strings"></a><span class="term">
      <code class="option">--compress-strings=&lt;no|yes&gt; [default: yes] </code>
    </span>
</dt>
<dd><p>This option influences the output format of the profile data.
      It specifies whether strings (file and function names) should be
      identified by numbers. This shrinks the file, 
      but makes it more difficult
      for humans to read (which is not recommended in any case).</p></dd>
<dt>
<a name="opt.compress-pos"></a><span class="term">
      <code class="option">--compress-pos=&lt;no|yes&gt; [default: yes] </code>
    </span>
</dt>
<dd><p>This option influences the output format of the profile data.
      It specifies whether numerical positions are always specified as absolute
      values or are allowed to be relative to previous numbers.
      This shrinks the file size,</p></dd>
<dt>
<a name="opt.combine-dumps"></a><span class="term">
      <code class="option">--combine-dumps=&lt;no|yes&gt; [default: no] </code>
    </span>
</dt>
<dd><p>When multiple profile data parts are to be generated, these
      parts are appended to the same output file if this option is set to
      "yes". Not recommended.</p></dd>
</dl>
</div>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.options.activity"></a>6.3.3. Activity options</h3></div></div></div>
<p>
These options specify when actions relating to event counts are to
be executed. For interactive control use
<code class="computeroutput">callgrind_control</code>.
</p>
<div class="variablelist">
<a name="cl.opts.list.activity"></a><dl>
<dt>
<a name="opt.dump-every-bb"></a><span class="term">
      <code class="option">--dump-every-bb=&lt;count&gt; [default: 0, never] </code>
    </span>
</dt>
<dd><p>Dump profile data every &lt;count&gt; basic blocks.
      Whether a dump is needed is only checked when Valgrind's internal
      scheduler is run. Therefore, the minimum setting useful is about 100000.
      The count is a 64-bit value to make long dump periods possible.
      </p></dd>
<dt>
<a name="opt.dump-before"></a><span class="term">
      <code class="option">--dump-before=&lt;function&gt; </code>
    </span>
</dt>
<dd><p>Dump when entering &lt;function&gt;</p></dd>
<dt>
<a name="opt.zero-before"></a><span class="term">
      <code class="option">--zero-before=&lt;function&gt; </code>
    </span>
</dt>
<dd><p>Zero all costs when entering &lt;function&gt;</p></dd>
<dt>
<a name="opt.dump-after"></a><span class="term">
      <code class="option">--dump-after=&lt;function&gt; </code>
    </span>
</dt>
<dd><p>Dump when leaving &lt;function&gt;</p></dd>
</dl>
</div>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.options.collection"></a>6.3.4. Data collection options</h3></div></div></div>
<p>
These options specify when events are to be aggregated into event counts.
Also see <a href="cl-manual.html#cl-manual.limits">Limiting range of event collection</a>.</p>
<div class="variablelist">
<a name="cl.opts.list.collection"></a><dl>
<dt>
<a name="opt.instr-atstart"></a><span class="term">
      <code class="option">--instr-atstart=&lt;yes|no&gt; [default: yes] </code>
    </span>
</dt>
<dd>
<p>Specify if you want Callgrind to start simulation and
      profiling from the beginning of the program.  
      When set to <code class="computeroutput">no</code>, 
      Callgrind will not be able
      to collect any information, including calls, but it will have at
      most a slowdown of around 4, which is the minimum Valgrind
      overhead.  Instrumentation can be interactively switched on via
      <code class="computeroutput">callgrind_control -i on</code>.</p>
<p>Note that the resulting call graph will most probably not
      contain <code class="computeroutput">main</code>, but will contain all the
      functions executed after instrumentation was switched on.
      Instrumentation can also programatically switched on/off. See the
      Callgrind include file
      <code class="computeroutput">&lt;callgrind.h&gt;</code> for the macro
      you have to use in your source code.</p>
<p>For cache
      simulation, results will be less accurate when switching on
      instrumentation later in the program run, as the simulator starts
      with an empty cache at that moment.  Switch on event collection
      later to cope with this error.</p>
</dd>
<dt>
<a name="opt.collect-atstart"></a><span class="term">
      <code class="option">--collect-atstart=&lt;yes|no&gt; [default: yes] </code>
    </span>
</dt>
<dd>
<p>Specify whether event collection is switched on at beginning
      of the profile run.</p>
<p>To only look at parts of your program, you have two
      possibilities:</p>
<div class="orderedlist"><ol type="1">
<li><p>Zero event counters before entering the program part you
        want to profile, and dump the event counters to a file after
        leaving that program part.</p></li>
<li><p>Switch on/off collection state as needed to only see
          event counters happening while inside of the program part you
          want to profile.</p></li>
</ol></div>
<p>The second option can be used if the program part you want to
      profile is called many times. Option 1, i.e. creating a lot of
      dumps is not practical here.</p>
<p>Collection state can be
      toggled at entry and exit of a given function with the
      option <a href="cl-manual.html#opt.toggle-collect">--toggle-collect</a>.  If you use this flag, 
      collection
      state should be switched off at the beginning.  Note that the
      specification of <code class="computeroutput">--toggle-collect</code>
      implicitly sets
      <code class="computeroutput">--collect-state=no</code>.</p>
<p>Collection state can be toggled also by using a Valgrind
      Client Request in your application.  For this, include
      <code class="computeroutput">valgrind/callgrind.h</code> and specify
      the macro
      <code class="computeroutput">CALLGRIND_TOGGLE_COLLECT</code> at the
      needed positions. This only will have any effect if run under
      supervision of the Callgrind tool.</p>
</dd>
<dt>
<a name="opt.toggle-collect"></a><span class="term">
      <code class="option">--toggle-collect=&lt;function&gt; </code>
    </span>
</dt>
<dd><p>Toggle collection on entry/exit of &lt;function&gt;.</p></dd>
<dt>
<a name="opt.collect-jumps"></a><span class="term">
      <code class="option">--collect-jumps=&lt;no|yes&gt; [default: no] </code>
    </span>
</dt>
<dd><p>This specifies whether information for (conditional) jumps
      should be collected.  As above, callgrind_annotate currently is not
      able to show you the data.  You have to use KCachegrind to get jump
      arrows in the annotated code.</p></dd>
</dl>
</div>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.options.separation"></a>6.3.5. Cost entity separation options</h3></div></div></div>
<p>
These options specify how event counts should be attributed to execution
contexts.
For example, they specify whether the recursion level or the
call chain leading to a function should be taken into account, 
and whether the thread ID should be considered.
Also see <a href="cl-manual.html#cl-manual.cycles">Avoiding cycles</a>.</p>
<div class="variablelist">
<a name="cmd-options.separation"></a><dl>
<dt>
<a name="opt.separate-threads"></a><span class="term">
      <code class="option">--separate-threads=&lt;no|yes&gt; [default: no] </code>
    </span>
</dt>
<dd><p>This option specifies whether profile data should be generated
      separately for every thread. If yes, the file names get "-threadID"
      appended.</p></dd>
<dt>
<a name="opt.separate-recs"></a><span class="term">
      <code class="option">--separate-recs=&lt;level&gt; [default: 2] </code>
    </span>
</dt>
<dd><p>Separate function recursions by at most &lt;level&gt; levels.
      See <a href="cl-manual.html#cl-manual.cycles">Avoiding cycles</a>.</p></dd>
<dt>
<a name="opt.separate-callers"></a><span class="term">
      <code class="option">--separate-callers=&lt;callers&gt; [default: 0] </code>
    </span>
</dt>
<dd><p>Separate contexts by at most &lt;callers&gt; functions in the
      call chain. See <a href="cl-manual.html#cl-manual.cycles">Avoiding cycles</a>.</p></dd>
<dt>
<a name="opt.skip-plt"></a><span class="term">
      <code class="option">--skip-plt=&lt;no|yes&gt; [default: yes] </code>
    </span>
</dt>
<dd><p>Ignore calls to/from PLT sections.</p></dd>
<dt>
<a name="opt.fn-skip"></a><span class="term">
      <code class="option">--fn-skip=&lt;function&gt; </code>
    </span>
</dt>
<dd>
<p>Ignore calls to/from a given function.  E.g. if you have a
      call chain A &gt; B &gt; C, and you specify function B to be
      ignored, you will only see A &gt; C.</p>
<p>This is very convenient to skip functions handling callback
      behaviour.  For example, with the signal/slot mechanism in the
      Qt graphics library, you only want
      to see the function emitting a signal to call the slots connected
      to that signal. First, determine the real call chain to see the
      functions needed to be skipped, then use this option.</p>
</dd>
<dt>
<a name="opt.fn-group"></a><span class="term">
      <code class="option">--fn-group&lt;number&gt;=&lt;function&gt; </code>
    </span>
</dt>
<dd><p>Put a function into a separate group. This influences the
      context name for cycle avoidance. All functions inside such a
      group are treated as being the same for context name building, which
      resembles the call chain leading to a context. By specifying function
      groups with this option, you can shorten the context name, as functions
      in the same group will not appear in sequence in the name. </p></dd>
<dt>
<a name="opt.separate-recs-num"></a><span class="term">
      <code class="option">--separate-recs&lt;number&gt;=&lt;function&gt; </code>
    </span>
</dt>
<dd><p>Separate &lt;number&gt; recursions for &lt;function&gt;.
      See <a href="cl-manual.html#cl-manual.cycles">Avoiding cycles</a>.</p></dd>
<dt>
<a name="opt.separate-callers-num"></a><span class="term">
      <code class="option">--separate-callers&lt;number&gt;=&lt;function&gt; </code>
    </span>
</dt>
<dd><p>Separate &lt;number&gt; callers for &lt;function&gt;.
      See <a href="cl-manual.html#cl-manual.cycles">Avoiding cycles</a>.</p></dd>
</dl>
</div>
</div>
<div class="sect2" lang="en">
<div class="titlepage"><div><div><h3 class="title">
<a name="cl-manual.options.simulation"></a>6.3.6. Cache simulation options</h3></div></div></div>
<div class="variablelist">
<a name="cl.opts.list.simulation"></a><dl>
<dt>
<a name="opt.simulate-cache"></a><span class="term">
      <code class="option">--simulate-cache=&lt;yes|no&gt; [default: no] </code>
    </span>
</dt>
<dd><p>Specify if you want to do full cache simulation.  By default,
      only instruction read accesses will be profiled.</p></dd>
<dt>
<a name="opt.simulate-hwpref"></a><span class="term">
      <code class="option">--simulate-hwpref=&lt;yes|no&gt; [default: no] </code>
    </span>
</dt>
<dd><p>Specify whether simulation of a hardware prefetcher should be
      added which is able to detect stream access in the second level cache
      by comparing accesses to separate to each page.
      As the simulation can not decide about any timing issues of prefetching,
      it is assumed that any hardware prefetch triggered succeeds before a
      real access is done. Thus, this gives a best-case scenario by covering
      all possible stream accesses.</p></dd>
</dl>
</div>
</div>
</div>
</div>
<div>
<br><table class="nav" width="100%" cellspacing="3" cellpadding="2" border="0" summary="Navigation footer">
<tr>
<td rowspan="2" width="40%" align="left">
<a accesskey="p" href="cg-manual.html">&lt;&lt; 5. Cachegrind: a cache and branch profiler</a> </td>
<td width="20%" align="center"><a accesskey="u" href="manual.html">Up</a></td>
<td rowspan="2" width="40%" align="right"> <a accesskey="n" href="hg-manual.html">7. Helgrind: a thread error detector &gt;&gt;</a>
</td>
</tr>
<tr><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td></tr>
</table>
</div>
</body>
</html>
